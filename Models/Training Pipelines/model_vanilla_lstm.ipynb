{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample events after preprocessing:\n",
      "             timestamp            type  \\\n",
      "16 2025-03-10 23:22:26     tabSwitched   \n",
      "17 2025-03-10 23:22:26  tabHighlighted   \n",
      "19 2025-03-10 23:22:27     tabSwitched   \n",
      "\n",
      "                                                 data  \n",
      "16  {'type': 'tabSwitched', 'fromTab': None, 'toTa...  \n",
      "17  {'type': 'tabHighlighted', 'windowId': 8379253...  \n",
      "19  {'type': 'tabSwitched', 'fromTab': 837925578, ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load the dataset from CSV\n",
    "df = pd.read_csv(\n",
    "    \"./user_data_qasim_1.csv\",  # path to the event log CSV\n",
    "    header=None,\n",
    "    on_bad_lines='skip',        # skip any malformed lines\n",
    "    encoding=\"cp1252\"           # encoding as used in the original file\n",
    ")\n",
    "\n",
    "# Assign column names for clarity\n",
    "df.columns = [\"timestamp\", \"type\", \"data\"]\n",
    "\n",
    "# 2. Convert timestamp column to datetime objects\n",
    "df['timestamp'] = pd.to_datetime(\n",
    "    df['timestamp'],\n",
    "    format='%Y-%m-%d %H:%M:%S',  # e.g., \"2025-03-10 23:21:05\" format\n",
    "    errors='coerce'             # invalid parsing will be set as NaT\n",
    ")\n",
    "\n",
    "# Drop any rows where timestamp conversion failed (NaT values)\n",
    "df = df.dropna(subset=['timestamp'])\n",
    "\n",
    "# 3. Filter out unwanted event types that are not needed for prediction\n",
    "df = df[\n",
    "    (df['type'] != 'memoryUsage') &\n",
    "    (df['type'] != 'tabDuration') &\n",
    "    (df['type'] != 'resourceUsage') &\n",
    "    (df['type'] != 'periodicBrowserStats')\n",
    "]\n",
    "\n",
    "# Drop any rows that are entirely NaN (if any remain after filtering)\n",
    "df = df.dropna()\n",
    "\n",
    "# 5. Sort events by timestamp to ensure chronological order of sequences\n",
    "df.sort_values(\"timestamp\", inplace=True)\n",
    "\n",
    "# (Optional) Quick check on the first few rows after preprocessing\n",
    "print(\"Sample events after preprocessing:\")\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequence Preperation for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadqasimatiqullah/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique event types (vocabulary size): 12\n",
      "Event type classes: ['tabAttached' 'tabCreated' 'tabDetached' 'tabHighlighted' 'tabRemoved'\n",
      " 'tabSwitched' 'tabTitleChanged' 'tabUpdated' 'userIdleStateChanged'\n",
      " 'windowCreated' 'windowFocused' 'windowRemoved']\n",
      "Number of training sequences: 3225\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Extract the sequence of event types from the cleaned DataFrame\n",
    "events = df['type'].values  # numpy array of event type strings in chronological order\n",
    "\n",
    "# Encode event types as integers\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_events = label_encoder.fit_transform(events)\n",
    "vocab_size = len(label_encoder.classes_)\n",
    "print(f\"Total unique event types (vocabulary size): {vocab_size}\")\n",
    "print(f\"Event type classes: {label_encoder.classes_}\")\n",
    "\n",
    "# Define sequence length (window size for input sequence of events)\n",
    "seq_length = 10  # chosen based on best performing configuration [oai_citation:8‡file-8z6kkayzrtyvq1o1e3hqbn](file://file-8z6kKaYzrTYVq1o1e3hQBn#:~:text=match%20at%20L1756%20,n)\n",
    "\n",
    "# Build sequences of events and the corresponding next-event targets\n",
    "sequences = []\n",
    "next_events = []\n",
    "for i in range(len(encoded_events) - seq_length):\n",
    "    # Extract a sequence of length seq_length\n",
    "    seq = encoded_events[i : i + seq_length]\n",
    "    sequences.append(seq)\n",
    "    # The event immediately following this sequence\n",
    "    next_events.append(encoded_events[i + seq_length])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "sequences = np.array(sequences)\n",
    "next_events = np.array(next_events)\n",
    "print(f\"Number of training sequences: {sequences.shape[0]}\")\n",
    "\n",
    "# One-hot encode the target (next event) classes for training\n",
    "y = to_categorical(next_events, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muhammadqasimatiqullah/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define hyperparameters for the model\n",
    "embedding_dim = 8    # dimension of embedding vectors for events (best found)\n",
    "lstm_units   = 16    # number of LSTM units (best found)\n",
    "learning_rate = 0.001\n",
    "batch_size    = 32   # training batch size\n",
    "\n",
    "# Build the Sequential model\n",
    "model = Sequential()\n",
    "# Embedding layer for event sequences\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=seq_length))\n",
    "# LSTM layer to learn sequence patterns\n",
    "model.add(LSTM(lstm_units))\n",
    "# Output layer with softmax activation for multi-class next-event prediction\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "# Compile the model with categorical crossentropy loss and Adam optimizer\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Summarize the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 - 1s - 9ms/step - accuracy: 0.3116 - loss: 2.0733 - val_accuracy: 0.3287 - val_loss: 1.6432\n",
      "Epoch 2/50\n",
      "81/81 - 0s - 2ms/step - accuracy: 0.3740 - loss: 1.5157 - val_accuracy: 0.4016 - val_loss: 1.4626\n",
      "Epoch 3/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.5519 - loss: 1.3911 - val_accuracy: 0.5721 - val_loss: 1.3818\n",
      "Epoch 4/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.5969 - loss: 1.3093 - val_accuracy: 0.5922 - val_loss: 1.3170\n",
      "Epoch 5/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6101 - loss: 1.2374 - val_accuracy: 0.5907 - val_loss: 1.2516\n",
      "Epoch 6/50\n",
      "81/81 - 0s - 2ms/step - accuracy: 0.6198 - loss: 1.1858 - val_accuracy: 0.6047 - val_loss: 1.2120\n",
      "Epoch 7/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6225 - loss: 1.1548 - val_accuracy: 0.6016 - val_loss: 1.1867\n",
      "Epoch 8/50\n",
      "81/81 - 0s - 2ms/step - accuracy: 0.6310 - loss: 1.1291 - val_accuracy: 0.6093 - val_loss: 1.1647\n",
      "Epoch 9/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6364 - loss: 1.1054 - val_accuracy: 0.6233 - val_loss: 1.1478\n",
      "Epoch 10/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6360 - loss: 1.0891 - val_accuracy: 0.6233 - val_loss: 1.1314\n",
      "Epoch 11/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6415 - loss: 1.0721 - val_accuracy: 0.6295 - val_loss: 1.1172\n",
      "Epoch 12/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6465 - loss: 1.0606 - val_accuracy: 0.6357 - val_loss: 1.1137\n",
      "Epoch 13/50\n",
      "81/81 - 0s - 2ms/step - accuracy: 0.6488 - loss: 1.0508 - val_accuracy: 0.6450 - val_loss: 1.1050\n",
      "Epoch 14/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6523 - loss: 1.0428 - val_accuracy: 0.6388 - val_loss: 1.0944\n",
      "Epoch 15/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6523 - loss: 1.0331 - val_accuracy: 0.6403 - val_loss: 1.0864\n",
      "Epoch 16/50\n",
      "81/81 - 0s - 2ms/step - accuracy: 0.6558 - loss: 1.0272 - val_accuracy: 0.6434 - val_loss: 1.0813\n",
      "Epoch 17/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6566 - loss: 1.0207 - val_accuracy: 0.6434 - val_loss: 1.0766\n",
      "Epoch 18/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6554 - loss: 1.0148 - val_accuracy: 0.6372 - val_loss: 1.0748\n",
      "Epoch 19/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6574 - loss: 1.0092 - val_accuracy: 0.6388 - val_loss: 1.0794\n",
      "Epoch 20/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6601 - loss: 1.0040 - val_accuracy: 0.6496 - val_loss: 1.0719\n",
      "Epoch 21/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6612 - loss: 1.0013 - val_accuracy: 0.6496 - val_loss: 1.0696\n",
      "Epoch 22/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6620 - loss: 0.9964 - val_accuracy: 0.6496 - val_loss: 1.0666\n",
      "Epoch 23/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6620 - loss: 0.9922 - val_accuracy: 0.6496 - val_loss: 1.0623\n",
      "Epoch 24/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6643 - loss: 0.9867 - val_accuracy: 0.6465 - val_loss: 1.0577\n",
      "Epoch 25/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6578 - loss: 0.9842 - val_accuracy: 0.6450 - val_loss: 1.0586\n",
      "Epoch 26/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6643 - loss: 0.9803 - val_accuracy: 0.6419 - val_loss: 1.0629\n",
      "Epoch 27/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6632 - loss: 0.9761 - val_accuracy: 0.6481 - val_loss: 1.0514\n",
      "Epoch 28/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6628 - loss: 0.9722 - val_accuracy: 0.6450 - val_loss: 1.0493\n",
      "Epoch 29/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6667 - loss: 0.9688 - val_accuracy: 0.6434 - val_loss: 1.0511\n",
      "Epoch 30/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6647 - loss: 0.9650 - val_accuracy: 0.6450 - val_loss: 1.0473\n",
      "Epoch 31/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6674 - loss: 0.9622 - val_accuracy: 0.6450 - val_loss: 1.0528\n",
      "Epoch 32/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6655 - loss: 0.9592 - val_accuracy: 0.6465 - val_loss: 1.0458\n",
      "Epoch 33/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6690 - loss: 0.9576 - val_accuracy: 0.6403 - val_loss: 1.0459\n",
      "Epoch 34/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6663 - loss: 0.9534 - val_accuracy: 0.6465 - val_loss: 1.0438\n",
      "Epoch 35/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6705 - loss: 0.9520 - val_accuracy: 0.6403 - val_loss: 1.0457\n",
      "Epoch 36/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6667 - loss: 0.9489 - val_accuracy: 0.6450 - val_loss: 1.0467\n",
      "Epoch 37/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6686 - loss: 0.9454 - val_accuracy: 0.6403 - val_loss: 1.0395\n",
      "Epoch 38/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6678 - loss: 0.9456 - val_accuracy: 0.6481 - val_loss: 1.0368\n",
      "Epoch 39/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6694 - loss: 0.9439 - val_accuracy: 0.6434 - val_loss: 1.0415\n",
      "Epoch 40/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6655 - loss: 0.9400 - val_accuracy: 0.6403 - val_loss: 1.0387\n",
      "Epoch 41/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6709 - loss: 0.9386 - val_accuracy: 0.6357 - val_loss: 1.0386\n",
      "Epoch 42/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6725 - loss: 0.9386 - val_accuracy: 0.6388 - val_loss: 1.0436\n",
      "Epoch 43/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6748 - loss: 0.9366 - val_accuracy: 0.6372 - val_loss: 1.0416\n",
      "Epoch 44/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6775 - loss: 0.9313 - val_accuracy: 0.6341 - val_loss: 1.0525\n",
      "Epoch 45/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6760 - loss: 0.9319 - val_accuracy: 0.6357 - val_loss: 1.0356\n",
      "Epoch 46/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6764 - loss: 0.9298 - val_accuracy: 0.6403 - val_loss: 1.0353\n",
      "Epoch 47/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6771 - loss: 0.9268 - val_accuracy: 0.6326 - val_loss: 1.0404\n",
      "Epoch 48/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6775 - loss: 0.9260 - val_accuracy: 0.6341 - val_loss: 1.0459\n",
      "Epoch 49/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6775 - loss: 0.9235 - val_accuracy: 0.6341 - val_loss: 1.0398\n",
      "Epoch 50/50\n",
      "81/81 - 0s - 1ms/step - accuracy: 0.6802 - loss: 0.9211 - val_accuracy: 0.6326 - val_loss: 1.0445\n"
     ]
    }
   ],
   "source": [
    "# Train the model, using 20% of data for validation to monitor performance\n",
    "epochs = 50  # number of epochs to train (best-performing value)\n",
    "history = model.fit(\n",
    "    sequences, \n",
    "    y,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,  # hold out 20% for validation each epoch\n",
    "    verbose=2  # verbose=2 for epoch-level logging\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as saved_vanilla_lstm.h5\n"
     ]
    }
   ],
   "source": [
    "# Save the trained model to an H5 file for later use (e.g., in a Flask app)\n",
    "model.save(\"saved_vanilla_lstm_new.h5\")\n",
    "print(\"Model saved as saved_vanilla_lstm.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
